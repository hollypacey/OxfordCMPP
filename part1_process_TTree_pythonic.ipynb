{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating:  .//./histograms/GamGam_pythonic\n"
     ]
    }
   ],
   "source": [
    "import uproot\n",
    "import pandas\n",
    "import awkward as ak\n",
    "import vector\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "luminosity_ifb = 10.\n",
    "\n",
    "def createDirs(path):\n",
    "    \"\"\"\n",
    "    Function to create any directories needed to store the output of a function.\n",
    "\n",
    "    Args:\n",
    "        path (str): the path of directories you want to exist\n",
    "\n",
    "    Returns:\n",
    "        void\n",
    "    \"\"\"\n",
    "    base = path.split(\"/\")[0]\n",
    "    dirs = path.split(\"/\")[:]\n",
    "    tmp_dir = \"\"\n",
    "    for folder in dirs:\n",
    "        tmp_dir = tmp_dir + \"/\" + folder\n",
    "        if not os.path.isdir(base+\"/\"+tmp_dir):\n",
    "            try:\n",
    "                os.mkdir(base+\"/\"+tmp_dir)\n",
    "                print(\"creating: \", base+\"/\"+tmp_dir)\n",
    "            except OSError as error:\n",
    "                print(error)\n",
    "\n",
    "# Define out input and output paths, make sure the output path exists.\n",
    "ntuple_path = \"./data/GamGam/\"\n",
    "output_path = \"./histograms/GamGam_pythonic/\"\n",
    "createDirs(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now vectorially process each event, retrieve the needed info from the ntuple, check if the event passes our selection, and fill histograms for the output.\n",
    "def eventLooper (tree, out_hists, is_data):\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO include the scaleFactor_PHOTON in the event weight, and the photon_isTightID branch.\n",
    "    branches = [\"photon_pt\", \"photon_E\", \"photon_eta\", \"photon_phi\", \"photon_n\", \"mcWeight\", \"XSection\", \"SumWeights\", \"scaleFactor_PILEUP\"]\n",
    "\n",
    "    # Read in the TTree to an Awkward Array (allows for vectors of branch values for each event rather than a pandas dataframe which must strcitly tabular.)\n",
    "    ## https://awkward-array.org/doc/main/ \n",
    "    df = ak.to_dataframe(uproot.concatenate(tree, filter_name = branches, library='ak'))\n",
    "\n",
    "    # get an idea of what this object looks like:\n",
    "    # note 'entries' are each event, 'subentries' are for each particle in the event.\n",
    "    print(df)\n",
    "\n",
    "    nentries = ak.num(df, axis=0)\n",
    "    print(\"there are {} event in the TTree\".format(nentries))\n",
    "\n",
    "    #hist_pTGam_1 = setupHist1D(out_hists, \"photon_pT_1\", 100, 0., 500., \"pT [GeV]\")\n",
    "    #hist_pTGam_2 = setupHist1D(out_hists, \"photon_pT_2\", 100, 0., 500., \"pT [GeV]\")\n",
    "    #hist_EGam_1 = setupHist1D(out_hists, \"photon_E_1\", 100, 0., 500., \"E [GeV]\")\n",
    "    #hist_EGam_2 = setupHist1D(out_hists, \"photon_E_2\", 100, 0., 500., \"E [GeV]\")\n",
    "    #hist_etaGam_1 = setupHist1D(out_hists, \"photon_eta_1\", 10, -2.5, 2.5, \"#eta\")\n",
    "    #hist_etaGam_2 = setupHist1D(out_hists, \"photon_eta_2\", 10, -2.5, 2.5, \"#eta\")\n",
    "    #hist_phiGam_1 = setupHist1D(out_hists, \"photon_phi_1\", 10, -4., 4., \"#phi\")\n",
    "    #hist_phiGam_2 = setupHist1D(out_hists, \"photon_phi_2\", 10, -4., 4., \"#phi\")\n",
    "    #hist_mGamGam = setupHist1D(out_hists, \"diphoton_mass\", 100, 0., 1000., \"m#gamma#gamma [GeV]\")\n",
    "\n",
    "    # read in the event weights\n",
    "    if (is_data):\n",
    "        df[\"histoweight\"] = 1.0\n",
    "    else:\n",
    "        # MC event weighting to luminosity of data\n",
    "        df[\"histoweight\"] = df[\"mcWeight\"] * df[\"XSection\"]*1000. * luminosity_ifb / df[\"SumWweights\"]\n",
    "        # MC weight corrections for experimental effects\n",
    "        df[\"histoweight\"] *= df[\"scaleFactor_PILEUP\"] # TODO multiply by the photon scale factor weight\n",
    "\n",
    "    # Only interested in events that have 2 photons in.\n",
    "    df.query(\"photon_n==2\", inplace=True)    \n",
    "    \n",
    "    # Obtain the kinematic variables (note TTree is in MeV and I want GeV)\n",
    "                # TODO we want to check that our photons 1/2 are ordered by their pT... can you alter the assignment here to ensure we have that?\n",
    "    df[\"photon_1_pt\"] = df[\"photon_pt\"][:,0]*0.001\n",
    "    df[\"photon_2_pt\"] = df[\"photon_pt\"][:,1]*0.001\n",
    "    df[\"photon_2_E\"] = df[\"photon_E\"][:,1]*0.001\n",
    "    df[\"photon_1_eta\"] = df[\"photon_eta\"][:,0]\n",
    "    df[\"photon_2_eta\"] = df[\"photon_eta\"][:,1]\n",
    "    df[\"photon_1_phi\"] = df[\"photon_phi\"][:,0]\n",
    "    df[\"photon_2_phi\"] = df[\"photon_phi\"][:,1]\n",
    "\n",
    "    # Need to check the photons are in the fiducial region\n",
    "    #eta_expr = abs(df[\"photon_1_eta\"]) < 2.37 and (abs(df[\"photon_1_eta\"]) < 1.37 or abs(df[\"photon_1_eta\"]) > 1.56) and \\\n",
    "    #           abs(df[\"photon_2_eta\"]) < 2.37 and (abs(df[\"photon_2_eta\"]) < 1.37 or abs(df[\"photon_2_eta\"]) > 1.56)\n",
    "    df[\"passEta\"] = abs(df[\"photon_1_eta\"]) < 2.37 and (abs(df[\"photon_1_eta\"]) < 1.37 or abs(df[\"photon_1_eta\"]) > 1.56) and \\\n",
    "               abs(df[\"photon_2_eta\"]) < 2.37 and (abs(df[\"photon_2_eta\"]) < 1.37 or abs(df[\"photon_2_eta\"]) > 1.56)\n",
    "    eta_expr.values\n",
    "    df.query(\"passEta\", inplace=True)\n",
    "        \n",
    "    # We need to apply the photon trigger requirements, approximated by requiring our photons to have photon 1(2) pT > 35(25) GeV\n",
    "    df.query(\"photon_1_pt > 35. & photon_2_pt > 25.\", inplace=True)\n",
    "\n",
    "    # TODO we're also only interested in the case where our two photons have passed a Tight particle ID, to reduce misreconstruction backgrounds.\n",
    "    # Can you use the boolean \"photon_isTightID\" vector branch to require this?..\n",
    "\n",
    "    photon_1_p4 = vector.arr( { 'pt' : df['photon_1_pt'],\n",
    "                           'eta' : df['photon_1_eta'],\n",
    "                           'phi' : df['photon_1_phi'],\n",
    "                           'E': df['photon_1_E']\n",
    "                           } )\n",
    "    photon_2_p4 = vector.arr( { 'pt' : df['photon_2_pt'],\n",
    "                           'eta' : df['photon_2_eta'],\n",
    "                           'phi' : df['photon_2_phi'],\n",
    "                           'E': df['photon_2_E']\n",
    "                           } )\n",
    "    \n",
    "    diphoton_p4 = photon_1_p4 + photon_2_p4\n",
    "    df[\"diphoton_mass\"] = diphoton_p4.m\n",
    "\n",
    "    # Another requiremt for good photons is a pT/diphoton mass bound\n",
    "    passRatio = (df['photon_1_pt']/df['diphoton_m'] > 0.35) & (df['photon_2_pt']/df['diphoton_m'] > 0.25)\n",
    "    df[\"passEnergyRatio\"] = passRatio\n",
    "    #df['passEnergyRatio'] = df['photon_isTightID']\n",
    "    #df.loc[(slice(None), 0), 'passEnergyRatio'] = passRatio.values\n",
    "    #df.loc[(slice(None), 1), 'passEnergyRatio'] = passRatio.values\n",
    "    df.query('passEnergyRatio', inplace=True)\n",
    "\n",
    "    print(df)\n",
    "\n",
    "        # Fill the histograms in the output file with the event values.\n",
    "        #hist_pTGam_1.Fill(photon_1_pt, histoweight)\n",
    "        #hist_pTGam_2.Fill(photon_2_pt, histoweight)\n",
    "        #hist_EGam_1.Fill(photon_1_E, histoweight)\n",
    "        #hist_EGam_2.Fill(photon_2_E, histoweight)\n",
    "        #hist_etaGam_1.Fill(photon_1_eta, histoweight)\n",
    "        #hist_etaGam_2.Fill(photon_2_eta, histoweight)\n",
    "        #hist_phiGam_1.Fill(photon_1_phi, histoweight)\n",
    "        #hist_phiGam_2.Fill(photon_2_phi, histoweight)\n",
    "        #hist_mGamGam.Fill(diphoton_mass, histoweight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  mcWeight  scaleFactor_PILEUP  photon_n     photon_pt  \\\n",
      "entry   subentry                                                         \n",
      "0       0              0.0                 0.0         2  46690.222656   \n",
      "        1              0.0                 0.0         2  29442.607422   \n",
      "1       0              0.0                 0.0         2  60888.738281   \n",
      "        1              0.0                 0.0         2  37795.011719   \n",
      "2       0              0.0                 0.0         2  39186.210938   \n",
      "...                    ...                 ...       ...           ...   \n",
      "7798421 1              0.0                 0.0         2  35773.832031   \n",
      "7798422 0              0.0                 0.0         2  72873.671875   \n",
      "        1              0.0                 0.0         2  45556.425781   \n",
      "7798423 0              0.0                 0.0         2  41198.300781   \n",
      "        1              0.0                 0.0         2  39577.066406   \n",
      "\n",
      "                  photon_eta  photon_phi       photon_E  XSection  SumWeights  \n",
      "entry   subentry                                                               \n",
      "0       0          -1.779089   -2.186474  142247.593750       1.0         1.0  \n",
      "        1           1.168063    1.127363   51918.000000       1.0         1.0  \n",
      "1       0           0.174119    1.859500   61814.070312       1.0         1.0  \n",
      "        1          -0.968964   -0.888251   56970.105469       1.0         1.0  \n",
      "2       0           0.139337    1.016534   39567.222656       1.0         1.0  \n",
      "...                      ...         ...            ...       ...         ...  \n",
      "7798421 1           0.870691    0.713682   50212.558594       1.0         1.0  \n",
      "7798422 0           0.935952    3.046246  107191.773438       1.0         1.0  \n",
      "        1          -0.666378    0.610477   56051.187500       1.0         1.0  \n",
      "7798423 0           0.311521   -0.288351   43213.570312       1.0         1.0  \n",
      "        1           1.109877    1.504822   66560.398438       1.0         1.0  \n",
      "\n",
      "[15623287 rows x 9 columns]\n",
      "there are 9 event in the TTree\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1455360/1879414029.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;31m# EventLoop analysis over the Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# write the file we will output our data histograms into (in .h5 and .csv format)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mout_df_data_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1455360/1424458774.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(tree, out_hists, is_data)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# Need to check the photons are in the fiducial region\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m#eta_expr = abs(df[\"photon_1_eta\"]) < 2.37 and (abs(df[\"photon_1_eta\"]) < 1.37 or abs(df[\"photon_1_eta\"]) > 1.56) and \\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m#           abs(df[\"photon_2_eta\"]) < 2.37 and (abs(df[\"photon_2_eta\"]) < 1.37 or abs(df[\"photon_2_eta\"]) > 1.56)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"passEta\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"photon_1_eta\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2.37\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"photon_1_eta\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1.37\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"photon_1_eta\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.56\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"photon_2_eta\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2.37\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"photon_2_eta\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1.37\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"photon_2_eta\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.56\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0meta_expr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"passEta\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CMPP/venv_pythonic/lib64/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1578\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "# EventLoop analysis over the Data \n",
    "\n",
    "# write the file we will output our data histograms into (in .h5 and .csv format)\n",
    "out_df_data_str = output_path+\"data\"\n",
    "\n",
    "# read in our data ntuples\n",
    "tree_data_str = ntuple_path+\"/Data/data_*.GamGam.root:mini\"\n",
    "\n",
    "# loop over the data ntuple to process needed info into histograms\n",
    "eventLooper(tree_data_str, out_df_data_str, True)\n",
    "# write data histograms to root file for further analysis.\n",
    "#out_hists_data.Write()\n",
    "#out_hists_data.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EventLoop analysis over the signal MC ntuples gluon gluon fusion -> H -> gamma gamma\n",
    "\n",
    "# write the file we will output our Higgs signal MC histograms into\n",
    "out_hists_ggfHiggs = TFile.Open(output_path+\"ggfHiggs.root\", \"RECREATE\")\n",
    "\n",
    "# read in our signal MC ntuples gluon gluon fusion -> H -> gamma gamma\n",
    "tree_ggfMC = TChain(\"mini\")\n",
    "tree_ggfMC.Add(ntuple_path+\"/MC/mc_343981.ggH125_gamgam.GamGam.root\")\n",
    "\n",
    "# loop over the data ntuple to process needed info into histograms\n",
    "eventLooper(tree_ggfMC, out_hists_ggfHiggs, False)\n",
    "# write data histograms to root file for further analysis.\n",
    "out_hists_ggfHiggs.Write()\n",
    "out_hists_ggfHiggs.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EventLoop analysis over the signal MC ntuples Vector-boson fusion -> H -> gamma gamma\n",
    "\n",
    "# write the file we will output our Higgs signal MC histograms into\n",
    "out_hists_vbfHiggs = TFile.Open(output_path+\"VBFHiggs.root\", \"RECREATE\")\n",
    "\n",
    "# read in our signal MC ntuples gluon gluon fusion -> H -> gamma gamma\n",
    "tree_vbfMC = TChain(\"mini\")\n",
    "tree_vbfMC.Add(ntuple_path+\"/MC/mc_345041.VBFH125_gamgam.GamGam.root\")\n",
    "\n",
    "# loop over the data ntuple to process needed info into histograms\n",
    "eventLooper(tree_vbfMC, out_hists_vbfHiggs, False)\n",
    "# write data histograms to root file for further analysis.\n",
    "out_hists_vbfHiggs.Write()\n",
    "out_hists_vbfHiggs.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now maybe we want to also have combined Signal MC Histograms containing both ggf and vbf production? can combine root files via hadd command:\n",
    "# and we can run a bash command via python as so....\n",
    "command = \"hadd -f histograms/GamGam/allHiggs.root histograms/GamGam/ggfHiggs.root histograms/GamGam/VBFHiggs.root\"\n",
    "print(command)\n",
    "os.system(command)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pythonic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
